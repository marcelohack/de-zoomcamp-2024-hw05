{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "519f4da6-b416-4fe0-a646-17e5dcad05ef",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n",
      "24/02/24 10:38:42 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n"
     ]
    }
   ],
   "source": [
    "import pyspark\n",
    "from pyspark.sql import SparkSession\n",
    "\n",
    "spark = SparkSession.builder \\\n",
    "    .master(\"local[*]\") \\\n",
    "    .appName('test_hw05_question2') \\\n",
    "    .getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "38f767bc-40e4-4c86-9b1f-2ba1d16765ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "!rm -rf data/raw/fhv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c0a84e5e-30c0-4670-a6a2-0ccfa3fb7238",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "downloading https://github.com/DataTalksClub/nyc-tlc-data/releases/download/fhv/fhv_tripdata_2019-10.csv.gz to data/raw/fhv/2019/10/fhv_tripdata_2019_10.csv.gz\n",
      "--2024-02-24 10:38:43--  https://github.com/DataTalksClub/nyc-tlc-data/releases/download/fhv/fhv_tripdata_2019-10.csv.gz\n",
      "Resolving github.com (github.com)... 20.248.137.48\n",
      "Connecting to github.com (github.com)|20.248.137.48|:443... connected.\n",
      "HTTP request sent, awaiting response... 302 Found\n",
      "Location: https://objects.githubusercontent.com/github-production-release-asset-2e65be/513814948/efdfcf82-6d5c-44d1-a138-4e8ea3c3a3b6?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=AKIAVCODYLSA53PQK4ZA%2F20240223%2Fus-east-1%2Fs3%2Faws4_request&X-Amz-Date=20240223T233729Z&X-Amz-Expires=300&X-Amz-Signature=0711832786147a0c8dfda6d6f7e748a14e936ee288fbb8c9faa53c972b674cf6&X-Amz-SignedHeaders=host&actor_id=0&key_id=0&repo_id=513814948&response-content-disposition=attachment%3B%20filename%3Dfhv_tripdata_2019-10.csv.gz&response-content-type=application%2Foctet-stream [following]\n",
      "--2024-02-24 10:38:43--  https://objects.githubusercontent.com/github-production-release-asset-2e65be/513814948/efdfcf82-6d5c-44d1-a138-4e8ea3c3a3b6?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=AKIAVCODYLSA53PQK4ZA%2F20240223%2Fus-east-1%2Fs3%2Faws4_request&X-Amz-Date=20240223T233729Z&X-Amz-Expires=300&X-Amz-Signature=0711832786147a0c8dfda6d6f7e748a14e936ee288fbb8c9faa53c972b674cf6&X-Amz-SignedHeaders=host&actor_id=0&key_id=0&repo_id=513814948&response-content-disposition=attachment%3B%20filename%3Dfhv_tripdata_2019-10.csv.gz&response-content-type=application%2Foctet-stream\n",
      "Resolving objects.githubusercontent.com (objects.githubusercontent.com)... 185.199.109.133, 185.199.110.133, 185.199.108.133, ...\n",
      "Connecting to objects.githubusercontent.com (objects.githubusercontent.com)|185.199.109.133|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 19375751 (18M) [application/octet-stream]\n",
      "Saving to: ‘data/raw/fhv/2019/10/fhv_tripdata_2019_10.csv.gz’\n",
      "\n",
      "data/raw/fhv/2019/1 100%[===================>]  18.48M  5.08MB/s    in 3.6s    \n",
      "\n",
      "2024-02-24 10:38:47 (5.16 MB/s) - ‘data/raw/fhv/2019/10/fhv_tripdata_2019_10.csv.gz’ saved [19375751/19375751]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "!./download_data.sh fhv 2019 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8e437267-85fa-4b9b-a09c-258b16603f3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "!gzip -d data/raw/fhv/2019/10/fhv_tripdata_2019_10.csv.gz # decompress to data/raw/fhv/2019/10/fhv_tripdata_2019_10.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "20cf5d1a-0bd1-4d7a-bce9-a94127c75924",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 1897494 data/raw/fhv/2019/10/fhv_tripdata_2019_10.csv\n"
     ]
    }
   ],
   "source": [
    "!wc -l data/raw/fhv/2019/10/fhv_tripdata_2019_10.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "44aa6c78-41b7-4664-a1a1-236bd85fa76a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = spark.read \\\n",
    "    .option(\"header\", \"true\") \\\n",
    "    .csv('data/raw/fhv/2019/10/fhv_tripdata_2019_10.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4a431e46-ac71-4408-ab38-4e0371f71b2e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "StructType([StructField('dispatching_base_num', StringType(), True), StructField('pickup_datetime', StringType(), True), StructField('dropOff_datetime', StringType(), True), StructField('PUlocationID', StringType(), True), StructField('DOlocationID', StringType(), True), StructField('SR_Flag', StringType(), True), StructField('Affiliated_base_number', StringType(), True)])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.schema"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e9d44186-57a6-4ec6-a393-f1860fd67396",
   "metadata": {},
   "outputs": [],
   "source": [
    "!head -n 100 data/raw/fhv/2019/10/fhv_tripdata_2019_10.csv > data/head.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b5d01f4c-610b-4ca7-82fb-078f454ccdcc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pandas in /Users/mhack/.pyenv/versions/3.10.3/envs/pyspark/lib/python3.10/site-packages (2.2.0)\n",
      "Requirement already satisfied: pyarrow in /Users/mhack/.pyenv/versions/3.10.3/envs/pyspark/lib/python3.10/site-packages (15.0.0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /Users/mhack/.pyenv/versions/3.10.3/envs/pyspark/lib/python3.10/site-packages (from pandas) (2024.1)\n",
      "Requirement already satisfied: numpy<2,>=1.22.4 in /Users/mhack/.pyenv/versions/3.10.3/envs/pyspark/lib/python3.10/site-packages (from pandas) (1.26.4)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /Users/mhack/.pyenv/versions/3.10.3/envs/pyspark/lib/python3.10/site-packages (from pandas) (2024.1)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /Users/mhack/.pyenv/versions/3.10.3/envs/pyspark/lib/python3.10/site-packages (from pandas) (2.8.2)\n",
      "Requirement already satisfied: six>=1.5 in /Users/mhack/.pyenv/versions/3.10.3/envs/pyspark/lib/python3.10/site-packages (from python-dateutil>=2.8.2->pandas) (1.16.0)\n",
      "\u001b[33mWARNING: You are using pip version 22.0.4; however, version 24.0 is available.\n",
      "You should consider upgrading via the '/Users/mhack/.pyenv/versions/3.10.3/envs/pyspark/bin/python3.10 -m pip install --upgrade pip' command.\u001b[0m\u001b[33m\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "!pip install pandas pyarrow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c5809c70-f1e2-401d-880d-ed2816190854",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "4a3021b5-7845-4129-a88b-ee105839e749",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_pandas = pd.read_csv('data/head.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "7a7251d1-4cc9-453e-b9dd-05ab452edf0f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dispatching_base_num       object\n",
       "pickup_datetime            object\n",
       "dropOff_datetime           object\n",
       "PUlocationID                int64\n",
       "DOlocationID                int64\n",
       "SR_Flag                   float64\n",
       "Affiliated_base_number     object\n",
       "dtype: object"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_pandas.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ff61c82b-63fc-44e8-9b69-dcb8a62f4812",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "StructType([StructField('dispatching_base_num', StringType(), True), StructField('pickup_datetime', StringType(), True), StructField('dropOff_datetime', StringType(), True), StructField('PUlocationID', LongType(), True), StructField('DOlocationID', LongType(), True), StructField('SR_Flag', DoubleType(), True), StructField('Affiliated_base_number', StringType(), True)])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spark.createDataFrame(df_pandas).schema"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "e980c4c2-83e9-4884-8de9-b439a266abe9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>dispatching_base_num</th>\n",
       "      <th>pickup_datetime</th>\n",
       "      <th>dropOff_datetime</th>\n",
       "      <th>PUlocationID</th>\n",
       "      <th>DOlocationID</th>\n",
       "      <th>SR_Flag</th>\n",
       "      <th>Affiliated_base_number</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>B00009</td>\n",
       "      <td>2019-10-01 00:23:00</td>\n",
       "      <td>2019-10-01 00:35:00</td>\n",
       "      <td>264</td>\n",
       "      <td>264</td>\n",
       "      <td>NaN</td>\n",
       "      <td>B00009</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>B00013</td>\n",
       "      <td>2019-10-01 00:11:29</td>\n",
       "      <td>2019-10-01 00:13:22</td>\n",
       "      <td>264</td>\n",
       "      <td>264</td>\n",
       "      <td>NaN</td>\n",
       "      <td>B00013</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>B00014</td>\n",
       "      <td>2019-10-01 00:11:43</td>\n",
       "      <td>2019-10-01 00:37:20</td>\n",
       "      <td>264</td>\n",
       "      <td>264</td>\n",
       "      <td>NaN</td>\n",
       "      <td>B00014</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>B00014</td>\n",
       "      <td>2019-10-01 00:56:29</td>\n",
       "      <td>2019-10-01 00:57:47</td>\n",
       "      <td>264</td>\n",
       "      <td>264</td>\n",
       "      <td>NaN</td>\n",
       "      <td>B00014</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>B00014</td>\n",
       "      <td>2019-10-01 00:23:09</td>\n",
       "      <td>2019-10-01 00:28:27</td>\n",
       "      <td>264</td>\n",
       "      <td>264</td>\n",
       "      <td>NaN</td>\n",
       "      <td>B00014</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>94</th>\n",
       "      <td>B00310</td>\n",
       "      <td>2019-10-01 00:12:11</td>\n",
       "      <td>2019-10-01 00:28:41</td>\n",
       "      <td>264</td>\n",
       "      <td>254</td>\n",
       "      <td>NaN</td>\n",
       "      <td>B00310</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>B00310</td>\n",
       "      <td>2019-10-01 00:06:02</td>\n",
       "      <td>2019-10-01 00:14:04</td>\n",
       "      <td>264</td>\n",
       "      <td>242</td>\n",
       "      <td>NaN</td>\n",
       "      <td>B00310</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>B00310</td>\n",
       "      <td>2019-10-01 00:03:43</td>\n",
       "      <td>2019-10-01 00:07:26</td>\n",
       "      <td>264</td>\n",
       "      <td>213</td>\n",
       "      <td>NaN</td>\n",
       "      <td>B02534</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>B00310</td>\n",
       "      <td>2019-10-01 00:37:14</td>\n",
       "      <td>2019-10-01 00:51:58</td>\n",
       "      <td>264</td>\n",
       "      <td>241</td>\n",
       "      <td>NaN</td>\n",
       "      <td>B02879</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>B00310</td>\n",
       "      <td>2019-10-01 00:42:41</td>\n",
       "      <td>2019-10-01 00:54:42</td>\n",
       "      <td>264</td>\n",
       "      <td>213</td>\n",
       "      <td>NaN</td>\n",
       "      <td>B02875</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>99 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   dispatching_base_num      pickup_datetime     dropOff_datetime  \\\n",
       "0                B00009  2019-10-01 00:23:00  2019-10-01 00:35:00   \n",
       "1                B00013  2019-10-01 00:11:29  2019-10-01 00:13:22   \n",
       "2                B00014  2019-10-01 00:11:43  2019-10-01 00:37:20   \n",
       "3                B00014  2019-10-01 00:56:29  2019-10-01 00:57:47   \n",
       "4                B00014  2019-10-01 00:23:09  2019-10-01 00:28:27   \n",
       "..                  ...                  ...                  ...   \n",
       "94               B00310  2019-10-01 00:12:11  2019-10-01 00:28:41   \n",
       "95               B00310  2019-10-01 00:06:02  2019-10-01 00:14:04   \n",
       "96               B00310  2019-10-01 00:03:43  2019-10-01 00:07:26   \n",
       "97               B00310  2019-10-01 00:37:14  2019-10-01 00:51:58   \n",
       "98               B00310  2019-10-01 00:42:41  2019-10-01 00:54:42   \n",
       "\n",
       "    PUlocationID  DOlocationID  SR_Flag Affiliated_base_number  \n",
       "0            264           264      NaN                 B00009  \n",
       "1            264           264      NaN                 B00013  \n",
       "2            264           264      NaN                 B00014  \n",
       "3            264           264      NaN                 B00014  \n",
       "4            264           264      NaN                 B00014  \n",
       "..           ...           ...      ...                    ...  \n",
       "94           264           254      NaN                 B00310  \n",
       "95           264           242      NaN                 B00310  \n",
       "96           264           213      NaN                 B02534  \n",
       "97           264           241      NaN                 B02879  \n",
       "98           264           213      NaN                 B02875  \n",
       "\n",
       "[99 rows x 7 columns]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "3cae4803-7043-4bf5-941d-329cf3f87596",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import types"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "c4fbcdbd-db84-47f5-b9cf-859075a8b76c",
   "metadata": {},
   "outputs": [],
   "source": [
    "schema = types.StructType([\n",
    "    types.StructField('dispatching_base_num', types.StringType(), True), \n",
    "    types.StructField('pickup_datetime', types.TimestampType(), True), \n",
    "    types.StructField('dropOff_datetime', types.TimestampType(), True),\n",
    "    types.StructField('PUlocationID', types.IntegerType(), True),\n",
    "    types.StructField('DOlocationID', types.IntegerType(), True),\n",
    "    types.StructField('SR_Flag', types.StringType(), True),\n",
    "    types.StructField('Affiliated_base_number', types.StringType(), True)\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "1e86345f-6a92-4bdc-bedb-734690a91678",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = spark.read \\\n",
    "    .option(\"header\", \"true\") \\\n",
    "    .schema(schema) \\\n",
    "    .csv('data/raw/fhv/2019/10/fhv_tripdata_2019_10.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "0d87481d-7986-433a-99da-15c998753852",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.repartition(6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "35417ec4-2596-4bc3-ac48-ef9ed04e5747",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "df.write.parquet('data/parquet/fhv/2019/10', mode = 'overwrite')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "b2b2556c-3d6c-4b2a-ab0a-fb8f4226b5a9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-rw-r--r--  1 mhack  staff   6.0M 24 Feb 10:38 data/parquet/fhv/2019/10/part-00000-5454eb70-e0a7-4fd6-807f-764e6161d714-c000.snappy.parquet\n",
      "-rw-r--r--  1 mhack  staff   6.0M 24 Feb 10:38 data/parquet/fhv/2019/10/part-00001-5454eb70-e0a7-4fd6-807f-764e6161d714-c000.snappy.parquet\n",
      "-rw-r--r--  1 mhack  staff   6.0M 24 Feb 10:38 data/parquet/fhv/2019/10/part-00002-5454eb70-e0a7-4fd6-807f-764e6161d714-c000.snappy.parquet\n",
      "-rw-r--r--  1 mhack  staff   6.0M 24 Feb 10:38 data/parquet/fhv/2019/10/part-00003-5454eb70-e0a7-4fd6-807f-764e6161d714-c000.snappy.parquet\n",
      "-rw-r--r--  1 mhack  staff   6.0M 24 Feb 10:38 data/parquet/fhv/2019/10/part-00004-5454eb70-e0a7-4fd6-807f-764e6161d714-c000.snappy.parquet\n",
      "-rw-r--r--  1 mhack  staff   6.0M 24 Feb 10:38 data/parquet/fhv/2019/10/part-00005-5454eb70-e0a7-4fd6-807f-764e6161d714-c000.snappy.parquet\n"
     ]
    }
   ],
   "source": [
    "!ls -lah data/parquet/fhv/2019/10/*.parquet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71343595-2aca-46ef-8657-ade13176e0e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('-- 6MB --')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
